# DeepFakes Manipulation

We use the [faceswap implementation from the deepfakes github](https://github.com/deepfakes/faceswap) for our generated DeepFakes videos. We made some changes to their implementation to make it fully automatic for our extracted videos. If you are interested in their current status, please head to the corresponding github.
We provide the source code that was used for our experiments as well as the scripts to produce new videos as well as to recreate our manipulated videos using our provided models.

## Example video
![example video](../../images/deepfakes.gif)

## Setup

### Instructions

- If you have not installed anaconda on your Ubuntu machine (such as a fresh AWS instance) you can run `bash setup.sh` to install the used cuda version and to setup the python environment (e.g., on a fresh Ubuntu). Here are the versions used in our environment (see the `setup.sh` script for commands to install them ob Ubuntu)
    - Python 3.6
    - Cuda 9.0.176-1
    - Cudnn 7.0.5.15-1
    - nccl 2_2.1.4-1
    - Python 3.5
    - pip install -r faceswap-master/requirements.txt
    - Opencv
    - tensorflow_gpu-1.10.1 
- Download the [face alignment cache](http://kaldir.vc.in.tum.de/faceforensics/models/DeepFakes_face_alignment_cache.zip) and merge it with the faceswap-master folder.

### Requirements for setup.sh

- Ubuntu 16.04 (without a prior anaconda installation)
- a Nvidia GPU with at least 8GB of memory (tested on GeForce 1080ti and K80)

## Usage

### Deepfakes Faceswap Git
For an explanation how to manipulate a single video/image collection using the faceswap github see their [instructions](faceswap-master/USAGE.md).

### Create Models
To generate DeepFakes models from a folder containing image folders that we extracted from our original sequences run
```shell
python deepfakes.py
    -i <path to image folders>
    -o <output path>
    --python_path <path to python file, e.g., /home/<user>/anaconda3/bin/python>
    -it 200000
    (--keep_temp_directories)
    (--convert_images)
```
Use `--keep_temp_directories` to generate all sub-folders that get generated by the DeepFakes pipeline, i.e., extracted faces used for training and alignment files. Use `--convert_images` to create the manipulated output images using our trained models.
We empirically used `200000` iterations for our experiments which had the best trade-off between image quality as well as training time. Note: you will need a powerful GPU to train these models in a reasonable time frame (around 1day/model depending on gpu).    

### Create Manipulated Images from Models
If you intend to alter the DeepFakes github post-processing pipeline, want to recreate the DeepFakes manipulated image sequences from our models on your own, or generate manipulated image sequences from your own trained models using the command above run
```shell
python deepfakes.py
    -m create_from_models
    -i <path to models folder>
    -i2 <input folder, e.g., path to 'original_sequences' folder>
    -o <output_path>
    --python_path <path to python file, e.g., /home/<user>/anaconda3/bin/python>
    (--filelist <path to filelist json that defines the pairs from the input folder (check out our filelist splits as an example)
```
   
 ## Masks
 In comparison to FaceSwap or Face2Face, it is not straightforward what to select as the DeepFakes manipulated area, i.e., mask, as this depends on the post-processing. Our current setup uses Poisson image editing to merge the manipulated area with the rest of the image. The DeepFakes masks in our dataset thus contain all areas where we apply the poisson image editing.
 
 ![original image](../../images/ex_original.png) ![deepfakes](../../images/ex_deepfakes.png) ![deepfakes](../../images/ex_deepfakes_mask.png)